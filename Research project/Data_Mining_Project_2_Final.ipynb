{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Mining_Project_2_Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd88FD87H6LK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This colab has the functions for cleaning, normalizing, and then performing RandomForest, KNN, and XGBoost on the CHO\n",
        "# and CIFAR datasets.\n",
        "# The main method is at the bottom, which prompts the user for a a choice of algorithm."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaZoNMZCIWkv",
        "colab_type": "code",
        "outputId": "92738f77-46c3-4689-f600-29b31155b479",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# will prompt for authorization\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7Y9ZHLmIgEY",
        "colab_type": "code",
        "outputId": "bc392695-56c4-44aa-9e8b-4b4a8ae3d633",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "# import packages\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "from math import *\n",
        "\n",
        "# for partitioning into training/test sets\n",
        "#from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "#from sklearn.datasets import make_classification\n",
        "from sklearn import svm\n",
        "# library for loading matlab files into python code\n",
        "from scipy.io import loadmat\n",
        "\n",
        "# libaries for evaluation\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn import metrics\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import cycle\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from scipy import interp\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "def load_datasets():\n",
        "  ############ Start with loading in and preparing the Cho dataset. ############\n",
        "  # load the Cho dataset\n",
        "  # put data into a matrix\n",
        "\n",
        "  '''This is Angie's import lines.''' \n",
        "  cho_array = np.loadtxt('/content/drive/My Drive/cse347_project_data/cho.txt')\n",
        "  \n",
        "  '''This is Lauren's import lines.'''  \n",
        "  #  cho_array = np.loadtxt('/content/drive/My Drive/Data_Mining/cho.txt')\n",
        "\n",
        "  # remove the gene_id AND ground truth from Cho array\n",
        "  new_cho_array = []\n",
        "  for item in cho_array:\n",
        "    new_cho_array.append(item)\n",
        "\n",
        "  j = 0\n",
        "  for i in new_cho_array:\n",
        "    i = i[2:]\n",
        "    new_cho_array[j] = i\n",
        "    j += 1\n",
        "\n",
        "\n",
        "  # normalize the data in each row using min/max method\n",
        "  # normalize all values to be within [0, 1]\n",
        "  new_max = 1\n",
        "  new_min = 0\n",
        "  j = 0\n",
        "  for item in new_cho_array:\n",
        "    max = item.max()\n",
        "    min = item.min()\n",
        "\n",
        "    k = 0\n",
        "    for i in item:\n",
        "      new_cho_array[j][k] = (((i - min)/(max - min)) * (new_max - new_min)) + new_min\n",
        "      k += 1\n",
        "    j += 1\n",
        "\n",
        "\n",
        "  # save ground truth in an array\n",
        "  ground_truth_array = []\n",
        "  for item in cho_array:\n",
        "    ground_truth_array.append(item[1])\n",
        "\n",
        "  # convert the ground truth to integers\n",
        "  index = 0\n",
        "  for i in ground_truth_array:\n",
        "    i = int(i)\n",
        "    ground_truth_array[index] = i\n",
        "    index += 1\n",
        "\n",
        "  ############ Now, work on loading in and preparing the CIFAR dataset. ############\n",
        "\n",
        "  # load CIFAR datasets\n",
        "  # each row is a color image, we can reshape and plot\n",
        "  # each image is 32x32x3  (3 for RGB)\n",
        "\n",
        "  '''These are Angie's import lines.'''\n",
        "  cifarBatch1 = loadmat('/content/drive/My Drive/cse347_project_data/cifar-10-batches-mat/data_batch_1.mat')\n",
        "  cifarBatch2 = loadmat('/content/drive/My Drive/cse347_project_data/cifar-10-batches-mat/data_batch_2.mat')\n",
        "  cifarBatch3 = loadmat('/content/drive/My Drive/cse347_project_data/cifar-10-batches-mat/data_batch_3.mat')\n",
        "  cifarBatch4 = loadmat('/content/drive/My Drive/cse347_project_data/cifar-10-batches-mat/data_batch_4.mat')\n",
        "  cifarBatch5 = loadmat('/content/drive/My Drive/cse347_project_data/cifar-10-batches-mat/data_batch_5.mat')\n",
        "  cifarTestBatch = loadmat('/content/drive/My Drive/cse347_project_data/cifar-10-batches-mat/test_batch.mat')\n",
        "\n",
        "  '''These are Lauren's import lines.'''\n",
        "  #  cifarBatch1 = loadmat('/content/drive/My Drive/Data_Mining/data_batch_1.mat')\n",
        "  #  cifarBatch2 = loadmat('/content/drive/My Drive/Data_Mining/data_batch_2.mat')\n",
        "  #  cifarBatch3 = loadmat('/content/drive/My Drive/Data_Mining/data_batch_3.mat')\n",
        "  #  cifarBatch4 = loadmat('/content/drive/My Drive/Data_Mining/data_batch_4.mat')\n",
        "  #  cifarBatch5 = loadmat('/content/drive/My Drive/Data_Mining/data_batch_5.mat')\n",
        "  #  cifarTestBatch = loadmat('/content/drive/My Drive/Data_Mining/test_batch.mat')\n",
        "\n",
        "  # separate the batches into their image and label sets\n",
        "  images_batch1 = cifarBatch1['data']\n",
        "  labels_for_batch1 = cifarBatch1['labels']\n",
        "\n",
        "  images_batch2 = cifarBatch2['data']\n",
        "  labels_for_batch2 = cifarBatch2['labels']\n",
        "\n",
        "  images_batch3 = cifarBatch3['data']\n",
        "  labels_for_batch3 = cifarBatch3['labels']\n",
        "\n",
        "  images_batch4 = cifarBatch4['data']\n",
        "  labels_for_batch4 = cifarBatch4['labels']\n",
        "\n",
        "  images_batch5 = cifarBatch5['data']\n",
        "  labels_for_batch5 = cifarBatch5['labels']\n",
        "\n",
        "  images_test_batch = cifarTestBatch['data']\n",
        "  labels_for_test_batch = cifarTestBatch['labels']\n",
        "\n",
        "  # put all of the batches together so we can run our own KFold\n",
        "  # we don't know how the creators of the dataset partitioned the data,\n",
        "    # so we want to do our own partitioning with KFold\n",
        "  cifarImages = []\n",
        "  for i in images_batch1:\n",
        "    cifarImages.append(i)\n",
        "  for i in images_batch2:\n",
        "    cifarImages.append(i)\n",
        "  for i in images_batch3:\n",
        "    cifarImages.append(i)\n",
        "  for i in images_batch4:\n",
        "    cifarImages.append(i)\n",
        "  for i in images_batch5:\n",
        "    cifarImages.append(i)\n",
        "  for i in images_test_batch:\n",
        "    cifarImages.append(i)\n",
        "\n",
        "\n",
        "  cifarLabels = []\n",
        "  for i in labels_for_batch1:\n",
        "    cifarLabels.append(i)\n",
        "  for i in labels_for_batch2:\n",
        "    cifarLabels.append(i)\n",
        "  for i in labels_for_batch3:\n",
        "    cifarLabels.append(i)\n",
        "  for i in labels_for_batch4:\n",
        "    cifarLabels.append(i)\n",
        "  for i in labels_for_batch5:\n",
        "    cifarLabels.append(i)\n",
        "  for i in labels_for_test_batch:\n",
        "    cifarLabels.append(i)\n",
        "\n",
        "  return [new_cho_array, ground_truth_array, cifarImages, cifarLabels]\n",
        "\n",
        "\n",
        "def Average(lst): \n",
        "    return sum(lst) / len(lst)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##################################################################################################################################\n",
        "##################################################################################################################################\n",
        "############################################ RANDOM FOREST FUNCTIONS #############################################################\n",
        "##################################################################################################################################\n",
        "##################################################################################################################################\n",
        "\n",
        "\n",
        "def rf_cho(cho_data, cho_labels):\n",
        "  # For CHO\n",
        "  # use the KFold library to get the training and testing sets\n",
        "  numpy_new_cho_array = np.array(cho_data)\n",
        "  numpy_ground_truth_array = np.array(cho_labels)\n",
        "\n",
        "  X = numpy_new_cho_array  # the data\n",
        "  y = numpy_ground_truth_array  # the labels\n",
        "\n",
        "  # initialize the KFold\n",
        "  kf = KFold(n_splits=5, random_state = 0, shuffle = True)\n",
        "  kf.get_n_splits(X)\n",
        "\n",
        "  #print(kf)\n",
        "\n",
        "  # these arrays will in the end hold the averages from each of the 5 folds\n",
        "  accuracy_averages = []\n",
        "  auc_averages = []\n",
        "  recall_averages = []\n",
        "\n",
        "  iteration = 0\n",
        "  for train_index, test_index in kf.split(X):\n",
        "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    # use the random forest classifier here inside the iteration\n",
        "\n",
        "    # Instantiate model with 100 decision trees\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state = 42)\n",
        "\n",
        "    # Train the model on training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Use the model to predict on the test set\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    #print (\"------  ------  ------  ------  ------\")\n",
        "\n",
        "    # ACCURACY\n",
        "    accuracy_cho = accuracy_score(y_test, predictions)\n",
        "    #print (\"CHO accuracy iteration:\", iteration, \"=\", accuracy_cho)\n",
        "    accuracy_averages.append(accuracy_cho)\n",
        "\n",
        "    # binarize the results here, not before hand\n",
        "    binarized_y_test_cho = label_binarize(y_test, classes=[1, 2, 3, 4, 5])\n",
        "    binarized_predictions_cho = label_binarize(predictions, classes=[1, 2, 3, 4, 5])\n",
        "    n_classes_cho = binarized_y_test_cho.shape[1]\n",
        "\n",
        "    # Compute ROC curve and ROC area for each class\n",
        "    fpr_cho = dict()\n",
        "    tpr_cho = dict()\n",
        "    roc_auc_cho = dict()\n",
        "    for i in range(n_classes_cho):\n",
        "      fpr_cho[i], tpr_cho[i], _ = roc_curve(binarized_y_test_cho[:, i], binarized_predictions_cho[:, i])\n",
        "      roc_auc_cho[i] = auc(fpr_cho[i], tpr_cho[i])\n",
        "    #print (\"CHO auc iteration\", iteration, \"=\", roc_auc_cho)\n",
        "    # first, compute the average of this run\n",
        "    sum_auc = 0\n",
        "    for j in range(0, len(roc_auc_cho)):\n",
        "      sum_auc += roc_auc_cho[j]\n",
        "    avg_auc = sum_auc/len(roc_auc_cho)\n",
        "    #print (\"Cho average auc: \", avg_auc)\n",
        "    # add this run's average to the list that will be averaged at the end of the 5 folds\n",
        "    auc_averages.append(avg_auc)\n",
        "\n",
        "    # RECALL\n",
        "    precision, recall_cho, f_score, support = precision_recall_fscore_support(y_test, predictions,  average=None)\n",
        "    #print (\"CHO recall iteration\", iteration, \"=\", recall_cho)\n",
        "    avg_recall = Average(recall_cho)\n",
        "    #print (\"Cho average recall: \", avg_recall)\n",
        "    recall_averages.append(avg_recall)\n",
        "\n",
        "    iteration += 1\n",
        "\n",
        "  overall_accuracy = Average(accuracy_averages)\n",
        "  std_accuracy = np.std(accuracy_averages)\n",
        "  #print (\"total accuracy: \", overall_accuracy)\n",
        "  overall_auc = Average(auc_averages)\n",
        "  std_auc = np.std(auc_averages)\n",
        "  #print (\"total auc: \", overall_auc)\n",
        "  overall_recall = Average(recall_averages)\n",
        "  std_recall = np.std(recall_averages)\n",
        "  #print (\"total recall: \", overall_recall)\n",
        "\n",
        "  # return the results of the various evaluation metrics\n",
        "  return [overall_accuracy, std_accuracy, overall_auc, std_auc, overall_recall, std_recall]\n",
        "\n",
        "\n",
        "def rf_cifar(cifarImages, cifarLabels):\n",
        "  # For CIFAR\n",
        "  # use the KFold library to get the training and testing sets\n",
        "  numpy_cifarImages = np.array(cifarImages)\n",
        "  numpy_cifarLabels = np.array(cifarLabels)\n",
        "\n",
        "  X_cifar = numpy_cifarImages  # the data\n",
        "  y_cifar = numpy_cifarLabels  # the labels\n",
        "\n",
        "  # initialize the KFold\n",
        "  kf = KFold(n_splits=5, random_state = 0, shuffle = True)\n",
        "  kf.get_n_splits(X_cifar)\n",
        "\n",
        "  #print(kf)\n",
        "\n",
        "  # create the arrays that will hold the averages/values for each of the 5 folds\n",
        "  accuracy_averages = []\n",
        "  auc_averages = []\n",
        "  recall_averages = []\n",
        "\n",
        "  iteration = 1\n",
        "  for train_index_cifar, test_index_cifar in kf.split(X_cifar):\n",
        "    #print (\"splitting\")\n",
        "    X_train_cifar, X_test_cifar = X_cifar[train_index_cifar], X_cifar[test_index_cifar]\n",
        "    y_train_cifar, y_test_cifar = y_cifar[train_index_cifar], y_cifar[test_index_cifar]\n",
        "\n",
        "    # use the random forest classifier here inside the iteration\n",
        "\n",
        "    # Instantiate model with 100 decision trees\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state = 42)\n",
        "\n",
        "    # Train the model on training data\n",
        "    model.fit(X_train_cifar, y_train_cifar)\n",
        "\n",
        "    # Use the model to predict on the test set\n",
        "    predictions_cifar = model.predict(X_test_cifar)\n",
        "\n",
        "    #print (\"------  ------  ------  ------  ------\")\n",
        "\n",
        "    # ACCURACY, not binarized\n",
        "    accuracy_cifar = accuracy_score(y_test_cifar, predictions_cifar)\n",
        "    #print (\"CIFAR accuracy iteration:\", iteration, \"=\", accuracy_cifar)\n",
        "    accuracy_averages.append(accuracy_cifar)\n",
        "\n",
        "    # binarize the results here, not before hand\n",
        "    binarized_y_test_cifar = label_binarize(y_test_cifar, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8 ,9])\n",
        "    binarized_predictions_cifar = label_binarize(predictions_cifar, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8 ,9])\n",
        "    n_classes_cifar = binarized_y_test_cifar.shape[1]\n",
        "\n",
        "    # Compute ROC curve and ROC area for each class\n",
        "    fpr_cifar = dict()\n",
        "    tpr_cifar = dict()\n",
        "    roc_auc_cifar = dict()\n",
        "    for i in range(n_classes_cifar):\n",
        "      fpr_cifar[i], tpr_cifar[i], _ = roc_curve(binarized_y_test_cifar[:, i], binarized_predictions_cifar[:, i])\n",
        "      roc_auc_cifar[i] = auc(fpr_cifar[i], tpr_cifar[i])\n",
        "    #print (\"CIFAR auc iteration\", iteration, \"=\", roc_auc_cifar)\n",
        "    # find the average from the values of this fold\n",
        "    sum_auc = 0\n",
        "    for j in range(0, len(roc_auc_cifar)):\n",
        "      sum_auc += roc_auc_cifar[j]\n",
        "    avg_auc = sum_auc/len(roc_auc_cifar)\n",
        "    #print (\"Cho average auc: \", avg_auc)\n",
        "    # add the average value to the array that will hold averaged values from all 5 folds\n",
        "    auc_averages.append(avg_auc)\n",
        "\n",
        "    # RECALL, not binarized\n",
        "    precision, recall_cifar, f_score, support = precision_recall_fscore_support(y_test_cifar, predictions_cifar, average=None)\n",
        "    #print (\"CIFAR recall iteration\", iteration, \"=\", recall_cifar)\n",
        "    avg_recall = Average(recall_cifar)\n",
        "    recall_averages.append(avg_recall)\n",
        "\n",
        "    iteration += 1\n",
        "\n",
        "  overall_accuracy = Average(accuracy_averages)\n",
        "  std_accuracy = np.std(accuracy_averages)\n",
        "  #print (\"total accuracy: \", overall_accuracy)\n",
        "  overall_auc = Average(auc_averages)\n",
        "  std_auc = np.std(auc_averages)\n",
        "  #print (\"total auc: \", overall_auc)\n",
        "  overall_recall = Average(recall_averages)\n",
        "  std_recall = np.std(recall_averages)\n",
        "  #print (\"total recall: \", overall_recall)\n",
        "\n",
        "  return [overall_accuracy, std_accuracy, overall_auc, std_auc, overall_recall, std_recall]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##################################################################################################################################\n",
        "##################################################################################################################################\n",
        "###################################################### KNN FUNCTIONS #############################################################\n",
        "##################################################################################################################################\n",
        "##################################################################################################################################\n",
        "\n",
        "def knn_cho(cho_data, cho_labels):\n",
        "  # For CHO\n",
        "  # use the KFold library to get the training and testing sets\n",
        "  numpy_new_cho_array = np.array(cho_data)\n",
        "  numpy_ground_truth_array = np.array(cho_labels)\n",
        "\n",
        "  X = numpy_new_cho_array  # the data\n",
        "  y = numpy_ground_truth_array  # the labels\n",
        "\n",
        "  # initialize the KFold\n",
        "  kf = KFold(n_splits=5, random_state = 4, shuffle = True)\n",
        "  kf.get_n_splits(X)\n",
        "\n",
        "  #print(kf)\n",
        "\n",
        "  # these arrays will in the end hold the averages from each of the 5 folds\n",
        "  accuracy_averages = []\n",
        "  auc_averages = []\n",
        "  recall_averages = []\n",
        "\n",
        "  iteration = 0\n",
        "  for train_index, test_index in kf.split(X):\n",
        "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "   \n",
        "    # use the knn classifier here inside the iteration\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state = 42)\n",
        "\n",
        "    # Train the model on training data\n",
        "    model = KNeighborsClassifier(n_neighbors=9)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Use the model to predict on the test set\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    #print (\"------  ------  ------  ------  ------\")\n",
        "\n",
        "    # ACCURACY\n",
        "    accuracy_cho = accuracy_score(y_test, predictions)\n",
        "    #print (\"CHO accuracy iteration:\", iteration, \"=\", accuracy_cho)\n",
        "    accuracy_averages.append(accuracy_cho)\n",
        "\n",
        "    # binarize the results here, not before hand\n",
        "    binarized_y_test_cho = label_binarize(y_test, classes=[1, 2, 3, 4, 5])\n",
        "    binarized_predictions_cho = label_binarize(predictions, classes=[1, 2, 3, 4, 5])\n",
        "    n_classes_cho = binarized_y_test_cho.shape[1]\n",
        "\n",
        "    # Compute ROC curve and ROC area for each class\n",
        "    fpr_cho = dict()\n",
        "    tpr_cho = dict()\n",
        "    roc_auc_cho = dict()\n",
        "    for i in range(n_classes_cho):\n",
        "      fpr_cho[i], tpr_cho[i], _ = roc_curve(binarized_y_test_cho[:, i], binarized_predictions_cho[:, i])\n",
        "      roc_auc_cho[i] = auc(fpr_cho[i], tpr_cho[i])\n",
        "    #print (\"CHO auc iteration\", iteration, \"=\", roc_auc_cho)\n",
        "    # first, compute the average of this run\n",
        "    sum_auc = 0\n",
        "    for j in range(0, len(roc_auc_cho)):\n",
        "      sum_auc += roc_auc_cho[j]\n",
        "    avg_auc = sum_auc/len(roc_auc_cho)\n",
        "    #print (\"Cho average auc: \", avg_auc)\n",
        "    # add this run's average to the list that will be averaged at the end of the 5 folds\n",
        "    auc_averages.append(avg_auc)\n",
        "\n",
        "    # RECALL\n",
        "    precision, recall_cho, f_score, support = precision_recall_fscore_support(y_test, predictions,  average=None)\n",
        "    #print (\"CHO recall iteration\", iteration, \"=\", recall_cho)\n",
        "    avg_recall = Average(recall_cho)\n",
        "    #print (\"Cho average recall: \", avg_recall)\n",
        "    recall_averages.append(avg_recall)\n",
        "\n",
        "    iteration += 1\n",
        "\n",
        "  overall_accuracy = Average(accuracy_averages)\n",
        "  std_accuracy = np.std(accuracy_averages)\n",
        "  #print (\"total accuracy: \", overall_accuracy)\n",
        "  overall_auc = Average(auc_averages)\n",
        "  std_auc = np.std(auc_averages)\n",
        "  #print (\"total auc: \", overall_auc)\n",
        "  overall_recall = Average(recall_averages)\n",
        "  std_recall = np.std(recall_averages)\n",
        "  #print (\"total recall: \", overall_recall)\n",
        "\n",
        "  # return the results of the various evaluation metrics\n",
        "  return [overall_accuracy, std_accuracy, overall_auc, std_auc, overall_recall, std_recall]\n",
        "\n",
        "\n",
        "def knn_cifar(cifarImages, cifarLabels):\n",
        "  # For CIFAR\n",
        "  # use the KFold library to get the training and testing sets\n",
        "  numpy_cifarImages = np.array(cifarImages)\n",
        "  numpy_cifarLabels = np.array(cifarLabels)\n",
        "\n",
        "  X_cifar = numpy_cifarImages  # the data\n",
        "  y_cifar = numpy_cifarLabels  # the labels\n",
        "\n",
        "  # initialize the KFold\n",
        "  kf = KFold(n_splits=5, random_state = 0, shuffle = True)\n",
        "  kf.get_n_splits(X_cifar)\n",
        "\n",
        "  #print(kf)\n",
        "\n",
        "  # create the arrays that will hold the averages/values for each of the 5 folds\n",
        "  accuracy_averages = []\n",
        "  auc_averages = []\n",
        "  recall_averages = []\n",
        "\n",
        "  iteration = 1\n",
        "  for train_index_cifar, test_index_cifar in kf.split(X_cifar):\n",
        "    #print (\"splitting\")\n",
        "    X_train_cifar, X_test_cifar = X_cifar[train_index_cifar], X_cifar[test_index_cifar]\n",
        "    y_train_cifar, y_test_cifar = y_cifar[train_index_cifar], y_cifar[test_index_cifar]\n",
        "\n",
        "    # use the random forest classifier here inside the iteration\n",
        "    model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "    # Train the model on training data\n",
        "    model.fit(X_train_cifar, y_train_cifar)\n",
        "\n",
        "    # Use the model to predict on the test set\n",
        "    predictions_cifar = model.predict(X_test_cifar)\n",
        "\n",
        "    #print (\"------  ------  ------  ------  ------\")\n",
        "\n",
        "    # ACCURACY, not binarized\n",
        "    accuracy_cifar = accuracy_score(y_test_cifar, predictions_cifar)\n",
        "    #print (\"CIFAR accuracy iteration:\", iteration, \"=\", accuracy_cifar)\n",
        "    accuracy_averages.append(accuracy_cifar)\n",
        "\n",
        "    # binarize the results here, not before hand\n",
        "    binarized_y_test_cifar = label_binarize(y_test_cifar, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8 ,9])\n",
        "    binarized_predictions_cifar = label_binarize(predictions_cifar, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8 ,9])\n",
        "    n_classes_cifar = binarized_y_test_cifar.shape[1]\n",
        "\n",
        "    # Compute ROC curve and ROC area for each class\n",
        "    fpr_cifar = dict()\n",
        "    tpr_cifar = dict()\n",
        "    roc_auc_cifar = dict()\n",
        "    for i in range(n_classes_cifar):\n",
        "      fpr_cifar[i], tpr_cifar[i], _ = roc_curve(binarized_y_test_cifar[:, i], binarized_predictions_cifar[:, i])\n",
        "      roc_auc_cifar[i] = auc(fpr_cifar[i], tpr_cifar[i])\n",
        "    #print (\"CIFAR auc iteration\", iteration, \"=\", roc_auc_cifar)\n",
        "    # find the average from the values of this fold\n",
        "    sum_auc = 0\n",
        "    for j in range(0, len(roc_auc_cifar)):\n",
        "      sum_auc += roc_auc_cifar[j]\n",
        "    avg_auc = sum_auc/len(roc_auc_cifar)\n",
        "    #print (\"Cho average auc: \", avg_auc)\n",
        "    # add the average value to the array that will hold averaged values from all 5 folds\n",
        "    auc_averages.append(avg_auc)\n",
        "\n",
        "    # RECALL, not binarized\n",
        "    precision, recall_cifar, f_score, support = precision_recall_fscore_support(y_test_cifar, predictions_cifar, average=None)\n",
        "    #print (\"CIFAR recall iteration\", iteration, \"=\", recall_cifar)\n",
        "    avg_recall = Average(recall_cifar)\n",
        "    recall_averages.append(avg_recall)\n",
        "\n",
        "    iteration += 1\n",
        "\n",
        "  overall_accuracy = Average(accuracy_averages)\n",
        "  std_accuracy = np.std(accuracy_averages)\n",
        "  #print (\"total accuracy: \", overall_accuracy)\n",
        "  overall_auc = Average(auc_averages)\n",
        "  std_auc = np.std(auc_averages)\n",
        "  #print (\"total auc: \", overall_auc)\n",
        "  overall_recall = Average(recall_averages)\n",
        "  std_recall = np.std(recall_averages)\n",
        "  #print (\"total recall: \", overall_recall)\n",
        "\n",
        "  return [overall_accuracy, std_accuracy, overall_auc, std_auc, overall_recall, std_recall]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##################################################################################################################################\n",
        "##################################################################################################################################\n",
        "###################################################### SVM FUNCTIONS #############################################################\n",
        "##################################################################################################################################\n",
        "##################################################################################################################################\n",
        "\n",
        "def svm_cho(cho_data, cho_labels):\n",
        "  # For CHO\n",
        "  # use the KFold library to get the training and testing sets\n",
        "  numpy_new_cho_array = np.array(cho_data)\n",
        "  numpy_ground_truth_array = np.array(cho_labels)\n",
        "\n",
        "  X = numpy_new_cho_array  # the data\n",
        "  y = numpy_ground_truth_array  # the labels\n",
        "\n",
        "  # initialize the KFold\n",
        "  kf = KFold(n_splits=5, random_state = 0, shuffle = True)\n",
        "  kf.get_n_splits(X)\n",
        "\n",
        "  #print(kf)\n",
        "\n",
        "  # these arrays will in the end hold the averages from each of the 5 folds\n",
        "  accuracy_averages = []\n",
        "  auc_averages = []\n",
        "  recall_averages = []\n",
        "\n",
        "  iteration = 0\n",
        "  for train_index, test_index in kf.split(X):\n",
        "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    # use the SVM classifier here inside the iteration\n",
        "\n",
        "    #creating the model and fitting to training data\n",
        "    svc = svm.SVC( kernel='rbf', random_state=7).fit(X_train, y_train)\n",
        "    #predicting values \n",
        "    y_pred = svc.predict(X_test)\n",
        "    predictions = [round(value) for value in y_pred]\n",
        "\n",
        "    #print (\"------  ------  ------  ------  ------\")\n",
        "\n",
        "    # ACCURACY\n",
        "    accuracy_cho = accuracy_score(y_test, predictions)\n",
        "    #print (\"CHO accuracy iteration:\", iteration, \"=\", accuracy_cho)\n",
        "    accuracy_averages.append(accuracy_cho)\n",
        "\n",
        "    # binarize the results here, not before hand\n",
        "    binarized_y_test_cho = label_binarize(y_test, classes=[1, 2, 3, 4, 5])\n",
        "    binarized_predictions_cho = label_binarize(predictions, classes=[1, 2, 3, 4, 5])\n",
        "    n_classes_cho = binarized_y_test_cho.shape[1]\n",
        "\n",
        "    # Compute ROC curve and ROC area for each class\n",
        "    fpr_cho = dict()\n",
        "    tpr_cho = dict()\n",
        "    roc_auc_cho = dict()\n",
        "    for i in range(n_classes_cho):\n",
        "      fpr_cho[i], tpr_cho[i], _ = roc_curve(binarized_y_test_cho[:, i], binarized_predictions_cho[:, i])\n",
        "      roc_auc_cho[i] = auc(fpr_cho[i], tpr_cho[i])\n",
        "    #print (\"CHO auc iteration\", iteration, \"=\", roc_auc_cho)\n",
        "    # first, compute the average of this run\n",
        "    sum_auc = 0\n",
        "    for j in range(0, len(roc_auc_cho)):\n",
        "      sum_auc += roc_auc_cho[j]\n",
        "    avg_auc = sum_auc/len(roc_auc_cho)\n",
        "    #print (\"Cho average auc: \", avg_auc)\n",
        "    # add this run's average to the list that will be averaged at the end of the 5 folds\n",
        "    auc_averages.append(avg_auc)\n",
        "\n",
        "    # RECALL\n",
        "    precision, recall_cho, f_score, support = precision_recall_fscore_support(y_test, predictions,  average=None)\n",
        "    #print (\"CHO recall iteration\", iteration, \"=\", recall_cho)\n",
        "    avg_recall = Average(recall_cho)\n",
        "    #print (\"Cho average recall: \", avg_recall)\n",
        "    recall_averages.append(avg_recall)\n",
        "\n",
        "    iteration += 1\n",
        "\n",
        "  overall_accuracy = Average(accuracy_averages)\n",
        "  std_accuracy = np.std(accuracy_averages)\n",
        "  #print (\"total accuracy: \", overall_accuracy)\n",
        "  overall_auc = Average(auc_averages)\n",
        "  std_auc = np.std(auc_averages)\n",
        "  #print (\"total auc: \", overall_auc)\n",
        "  overall_recall = Average(recall_averages)\n",
        "  std_recall = np.std(recall_averages)\n",
        "  #print (\"total recall: \", overall_recall)\n",
        "\n",
        "  # return the results of the various evaluation metrics\n",
        "  return [overall_accuracy, std_accuracy, overall_auc, std_auc, overall_recall, std_recall]\n",
        "\n",
        "\n",
        "def svm_cifar(cifarImages, cifarLabels):\n",
        "  # For CIFAR\n",
        "  # use the KFold library to get the training and testing sets\n",
        "  numpy_cifarImages = np.array(cifarImages)\n",
        "  numpy_cifarLabels = np.array(cifarLabels)\n",
        "\n",
        "  X_cifar = numpy_cifarImages  # the data\n",
        "  y_cifar = numpy_cifarLabels  # the labels\n",
        "\n",
        "  # initialize the KFold\n",
        "  kf = KFold(n_splits=5, random_state = 0, shuffle = True)\n",
        "  kf.get_n_splits(X_cifar)\n",
        "  \n",
        "  # create the arrays that will hold the averages/values for each of the 5 folds\n",
        "  accuracy_averages = []\n",
        "  auc_averages = []\n",
        "  recall_averages = []\n",
        "\n",
        "  iteration = 1\n",
        "  for train_index_cifar, test_index_cifar in kf.split(X_cifar):\n",
        " \n",
        "    X_train_cifar, X_test_cifar = X_cifar[train_index_cifar], X_cifar[test_index_cifar]\n",
        "    y_train_cifar, y_test_cifar = y_cifar[train_index_cifar], y_cifar[test_index_cifar]\n",
        "\n",
        "\n",
        "    #creating the model and fitting to training data\n",
        "    svc = svm.SVC( kernel='rbf', random_state=7)\n",
        "    model = svc.fit(X_train_cifar, y_train_cifar.ravel())\n",
        "\n",
        "    #predicting values\n",
        "    y_pred_cifar = model.predict(X_test_cifar)\n",
        "    predictions_cifar = [round(value) for value in y_pred_cifar]\n",
        "\n",
        "    #print (\"------  ------  ------  ------  ------\")\n",
        "\n",
        "    # ACCURACY, not binarized\n",
        "    accuracy_cifar = accuracy_score(y_test_cifar, predictions_cifar)\n",
        "    #print (\"CIFAR accuracy iteration:\", iteration, \"=\", accuracy_cifar)\n",
        "    accuracy_averages.append(accuracy_cifar)\n",
        "\n",
        "    # binarize the results here, not before hand\n",
        "    binarized_y_test_cifar = label_binarize(y_test_cifar, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8 ,9])\n",
        "    binarized_predictions_cifar = label_binarize(predictions_cifar, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8 ,9])\n",
        "    n_classes_cifar = binarized_y_test_cifar.shape[1]\n",
        "\n",
        "    # Compute ROC curve and ROC area for each class\n",
        "    fpr_cifar = dict()\n",
        "    tpr_cifar = dict()\n",
        "    roc_auc_cifar = dict()\n",
        "    for i in range(n_classes_cifar):\n",
        "      fpr_cifar[i], tpr_cifar[i], _ = roc_curve(binarized_y_test_cifar[:, i], binarized_predictions_cifar[:, i])\n",
        "      roc_auc_cifar[i] = auc(fpr_cifar[i], tpr_cifar[i])\n",
        "    #print (\"CIFAR auc iteration\", iteration, \"=\", roc_auc_cifar)\n",
        "    # find the average from the values of this fold\n",
        "    sum_auc = 0\n",
        "    for j in range(0, len(roc_auc_cifar)):\n",
        "      sum_auc += roc_auc_cifar[j]\n",
        "    avg_auc = sum_auc/len(roc_auc_cifar)\n",
        "    #print (\"Cho average auc: \", avg_auc)\n",
        "    # add the average value to the array that will hold averaged values from all 5 folds\n",
        "    auc_averages.append(avg_auc)\n",
        "\n",
        "    # RECALL, not binarized\n",
        "    precision, recall_cifar, f_score, support = precision_recall_fscore_support(y_test_cifar, predictions_cifar, average=None)\n",
        "    #print (\"CIFAR recall iteration\", iteration, \"=\", recall_cifar)\n",
        "    avg_recall = Average(recall_cifar)\n",
        "    recall_averages.append(avg_recall)\n",
        "\n",
        "    iteration += 1\n",
        "\n",
        "  overall_accuracy = Average(accuracy_averages)\n",
        "  std_accuracy = np.std(accuracy_averages)\n",
        "  #print (\"total accuracy: \", overall_accuracy)\n",
        "  overall_auc = Average(auc_averages)\n",
        "  std_auc = np.std(auc_averages)\n",
        "  #print (\"total auc: \", overall_auc)\n",
        "  overall_recall = Average(recall_averages)\n",
        "  std_recall = np.std(recall_averages)\n",
        "  #print (\"total recall: \", overall_recall)\n",
        "\n",
        "  return [overall_accuracy, std_accuracy, overall_auc, std_auc, overall_recall, std_recall]\n",
        "\n",
        "\n",
        "##################################################################################################################################\n",
        "##################################################################################################################################\n",
        "############################################ CALLS TO THE DIFFERENT ALGORITHMS ###################################################\n",
        "##################################################################################################################################\n",
        "##################################################################################################################################\n",
        "\n",
        "\n",
        "\n",
        "def random_forest():\n",
        "  # get the cho and CIFAR data sets\n",
        "  # datasets = [cho_data, cho_labels, cifarImages, cifarLabels]\n",
        "  # these datasets will have been cleaned/normalized as appropriate\n",
        "  datasets = load_datasets()\n",
        "  cho_data = datasets[0]\n",
        "  cho_labels = datasets[1]\n",
        "  cifarImages = datasets[2]\n",
        "  cifarLabels = datasets[3]\n",
        "\n",
        "  print (\"Calculating for Cho...\")\n",
        "  # call the random forrest method for Cho\n",
        "  # returns [overall_accuracy, overall_auc, overall_recall]\n",
        "  results_rf_cho = rf_cho(cho_data, cho_labels)\n",
        "\n",
        "  # print the results for Cho:\n",
        "  print ()\n",
        "  print (\"\\n\\nThe accuracy of the Cho dataset:\")\n",
        "  print (results_rf_cho[0])\n",
        "  print (\"The standard deviation for accuracy:\")\n",
        "  print (results_rf_cho[1])\n",
        "  print ()\n",
        "  print (\"The AUC of the Cho dataset:\")\n",
        "  print (results_rf_cho[2])\n",
        "  print (\"The standard deviation for AUC:\")\n",
        "  print (results_rf_cho[3])\n",
        "  print ()\n",
        "  print (\"The recall of the Cho dataset:\")\n",
        "  print (results_rf_cho[4])\n",
        "  print (\"The standard deviation for recall:\")\n",
        "  print (results_rf_cho[5])\n",
        "  print ()\n",
        "\n",
        "  print ()\n",
        "  print (\"Calculating for CIFAR...\")\n",
        "  print ()\n",
        "\n",
        "  # call the random forrest method for CIFAR\n",
        "  # returns [overall_accuracy, overall_auc, overall_recall]\n",
        "  results_rf_cifar = rf_cifar(cifarImages, cifarLabels)\n",
        "\n",
        "  # print the results for CIFAR\n",
        "  print ()\n",
        "  print (\"\\n\\nThe accuracy of the Cho dataset:\")\n",
        "  print (results_rf_cifar[0])\n",
        "  print (\"The standard deviation for accuracy:\")\n",
        "  print (results_rf_cifar[1])\n",
        "  print ()\n",
        "  print (\"The AUC of the Cho dataset:\")\n",
        "  print (results_rf_cifar[2])\n",
        "  print (\"The standard deviation for AUC:\")\n",
        "  print (results_rf_cifar[3])\n",
        "  print ()\n",
        "  print (\"The recall of the Cho dataset:\")\n",
        "  print (results_rf_cifar[4])\n",
        "  print (\"The standard deviation for recall:\")\n",
        "  print (results_rf_cifar[5])\n",
        "  print ()\n",
        "\n",
        "\n",
        "\n",
        "def KNN():\n",
        "  # get the cho and CIFAR data sets\n",
        "  # datasets = [cho_array, cifarImages, cifarLabels]\n",
        "  # these datasets will have been cleaned/normalized as appropriate\n",
        "  datasets = load_datasets()\n",
        "  cho_data = datasets[0]\n",
        "  cho_labels = datasets[1]\n",
        "  cifarImages = datasets[2]\n",
        "  cifarLabels = datasets[3]\n",
        "\n",
        "  print (\"Calculating for Cho...\")\n",
        "  # call the random forrest method for Cho\n",
        "  # returns [overall_accuracy, overall_auc, overall_recall]\n",
        "  results_knn_cho = knn_cho(cho_data, cho_labels)\n",
        "\n",
        "  # print the results for Cho:\n",
        "  print ()\n",
        "  print (\"\\n\\nThe accuracy of the Cho dataset:\")\n",
        "  print (results_knn_cho[0])\n",
        "  print (\"The standard deviation for accuracy:\")\n",
        "  print (results_knn_cho[1])\n",
        "  print ()\n",
        "  print (\"The AUC of the Cho dataset:\")\n",
        "  print (results_knn_cho[2])\n",
        "  print (\"The standard deviation for AUC:\")\n",
        "  print (results_knn_cho[3])\n",
        "  print ()\n",
        "  print (\"The recall of the Cho dataset:\")\n",
        "  print (results_knn_cho[4])\n",
        "  print (\"The standard deviation for recall:\")\n",
        "  print (results_knn_cho[5])\n",
        "  print ()\n",
        "\n",
        "\n",
        "  print (\"Calculating for CIFAR...\")\n",
        "  print ()\n",
        "  # call the random forrest method for CIFAR\n",
        "  # returns [overall_accuracy, overall_auc, overall_recall]\n",
        "  results_knn_cifar = knn_cifar(cifarImages, cifarLabels)\n",
        "\n",
        "  # print the results for CIFAR\n",
        "  print ()\n",
        "  print (\"\\n\\nThe accuracy of the CIFAR dataset:\")\n",
        "  print (results_knn_cifar[0])\n",
        "  print (\"The standard deviation for accuracy: \")\n",
        "  print (results_knn_cifar[1])\n",
        "  print ()\n",
        "  print (\"The AUC of the CIFAR dataset: \")\n",
        "  print (results_knn_cifar[2])\n",
        "  print (\"The standard deviation for AUC:\")\n",
        "  print (results_knn_cifar[3])\n",
        "  print ()\n",
        "  print (\"The recall of the CIFAR dataset: \")\n",
        "  print (results_knn_cifar[4])\n",
        "  print (\"The standard deviation for recall:\")\n",
        "  print (results_knn_cifar[5])\n",
        "  print ()\n",
        "\n",
        "\n",
        "\n",
        "def SVM():\n",
        "  # get the cho and CIFAR data sets\n",
        "  # datasets = [cho_data, cho_labels, cifarImages, cifarLabels]\n",
        "  # these datasets will have been cleaned/normalized as appropriate\n",
        "  datasets = load_datasets()\n",
        "  cho_data = datasets[0]\n",
        "  cho_labels = datasets[1]\n",
        "  cifarImages = datasets[2]\n",
        "  cifarLabels = datasets[3]\n",
        "\n",
        "  print (\"Calculating for Cho...\")\n",
        "  # call the random forrest method for Cho\n",
        "  # returns [overall_accuracy, overall_auc, overall_recall]\n",
        "  results_svm_cho = svm_cho(cho_data, cho_labels)\n",
        "\n",
        "  # print the results for Cho:\n",
        "  print ()\n",
        "  print (\"\\n\\nThe accuracy of the Cho dataset:\")\n",
        "  print (results_svm_cho[0])\n",
        "  print (\"The standard deviation for accuracy:\")\n",
        "  print (results_svm_cho[1])\n",
        "  print ()\n",
        "  print (\"The AUC of the Cho dataset:\")\n",
        "  print (results_svm_cho[2])\n",
        "  print (\"The standard deviation for AUC:\")\n",
        "  print (results_svm_cho[3])\n",
        "  print ()\n",
        "  print (\"The recall of the Cho dataset:\")\n",
        "  print (results_svm_cho[4])\n",
        "  print (\"The standard deviation for recall:\")\n",
        "  print (results_svm_cho[5])\n",
        "  print ()\n",
        "\n",
        "  print ()\n",
        "  print (\"Calculating for CIFAR...\")\n",
        "  print ()\n",
        "\n",
        "  # call the random forrest method for CIFAR\n",
        "  # returns [overall_accuracy, overall_auc, overall_recall]\n",
        "  results_svm_cifar = svm_cifar(cifarImages, cifarLabels)\n",
        "\n",
        "  # print the results for CIFAR\n",
        "  print ()\n",
        "  print (\"\\n\\nThe accuracy of the Cho dataset:\")\n",
        "  print (results_svm_cifar[0])\n",
        "  print (\"The standard deviation for accuracy:\")\n",
        "  print (results_svm_cifar[1])\n",
        "  print ()\n",
        "  print (\"The AUC of the Cho dataset:\")\n",
        "  print (results_svm_cifar[2])\n",
        "  print (\"The standard deviation for AUC:\")\n",
        "  print (results_svm_cifar[3])\n",
        "  print ()\n",
        "  print (\"The recall of the Cho dataset:\")\n",
        "  print (results_svm_cifar[4])\n",
        "  print (\"The standard deviation for recall:\")\n",
        "  print (results_svm_cifar[5])\n",
        "  print ()\n",
        "\n",
        "\n",
        "\n",
        "##################################################################################################################################\n",
        "##################################################################################################################################\n",
        "######################################################   MAIN METHOD    ##########################################################\n",
        "##################################################################################################################################\n",
        "##################################################################################################################################\n",
        "                                                    \n",
        "# ask the user what method they want to use, either:\n",
        "  # Random Forest\n",
        "  # KNN\n",
        "  # SVM\n",
        "\n",
        "loop = 1\n",
        "while (loop):\n",
        "  method = input(\"Enter r for random forest or k for KNN or s for SVM:\\n\")\n",
        "  if (method == 'r'):\n",
        "    loop = 0\n",
        "    # call Random Forest function\n",
        "    random_forest()\n",
        "  \n",
        "  elif (method == 'k'):\n",
        "    loop = 0\n",
        "    # call KNN function\n",
        "    KNN()\n",
        "\n",
        "  elif (method == 's'):\n",
        "    loop = 0\n",
        "    # call SVM function\n",
        "    SVM()\n",
        "\n",
        "  else:\n",
        "    print (\"That is not an option.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating for Cho...\n",
            "\n",
            "\n",
            "\n",
            "The accuracy of the Cho dataset:\n",
            "0.7382950382950384\n",
            "The standard deviation for accuracy:\n",
            "0.021286093952511305\n",
            "\n",
            "The AUC of the Cho dataset:\n",
            "0.8282064465265668\n",
            "The standard deviation for AUC:\n",
            "0.012202015198283728\n",
            "\n",
            "The recall of the Cho dataset:\n",
            "0.7248322768621958\n",
            "The standard deviation for recall:\n",
            "0.019762121229298154\n",
            "\n",
            "Calculating for CIFAR...\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:481: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:481: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:481: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:481: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:481: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "The accuracy of the CIFAR dataset:\n",
            "0.33875\n",
            "The standard deviation for accuracy: \n",
            "0.004277525245071298\n",
            "\n",
            "The AUC of the CIFAR dataset: \n",
            "0.6327039802311446\n",
            "The standard deviation for AUC:\n",
            "0.0015841486437533556\n",
            "\n",
            "The recall of the CIFAR dataset: \n",
            "0.3388772107490549\n",
            "The standard deviation for recall:\n",
            "0.0027481521259026284\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}